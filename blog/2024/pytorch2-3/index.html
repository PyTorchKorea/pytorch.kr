<!DOCTYPE html>
<html lang="ko">
<head>
<!-- Google Tag Manager -->
<script data-cfasync="false">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-57L6X5C');</script>
<!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      PyTorch 2.3 출시 공지 | 파이토치 한국 사용자 모임
    
  </title>
  <meta property="og:title" content="파이토치 한국 사용자 모임 (PyTorch Korea User Group)" />
<meta
  name="description"
  property="og:description"
  content="파이토치 한국 사용자 모임에 오신 것을 환영합니다. 딥러닝 프레임워크인 파이토치(PyTorch)를 사용하는 한국어 사용자들을 위해 문서를 번역하고 정보를 공유하고 있습니다."
/>
<meta property="og:url" content="https://pytorch.kr" />
<meta property="og:type" content="website" />
<meta
  property="og:image"
  content="https://pytorch.kr/assets/images/pytorch-kr-logo.png"
/>
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript data-cfasync="false"><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-57L6X5C"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>

    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorchKR"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">시작하기</a>
    </li>

    <li class="main-menu-item active">
      <a href="/blog">블로그</a>
    </li>

    <li class="main-menu-item">
      <a href="https://tutorials.pytorch.kr/" target="_self">튜토리얼</a>
    </li>

    <li class="main-menu-item ">
      <a href="/hub">허브</a>
    </li>

    <li class="main-menu-item">
      <a href="https://discuss.pytorch.kr/" target="_self">커뮤니티</a>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">April 24, 2024</p>
            <h1><a class="blog-title">PyTorch 2.3 출시 공지</a></h1>
            
                <h4 class="blog-subtitle">PyTorch 2.3 Release Blog</h4>
            
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      
                        
                            작성: PyTorch Team, 번역: PyTorch Korea User Group
                        
                      
                    </p>
                    
                    <p class="translation-description">
                        이 글은 <a href="https://pytorch.org/blog/">PyTorch 공식 블로그</a>의 글을 번역한 것입니다.
                        번역 글은 원문을 함께 표시합니다. 원문을 읽으시려면 <a href="https://pytorch.org/blog/pytorch2-3/">여기</a>를 클릭하세요.
                        (This article is a Korean translation of the original post on the <a href="https://pytorch.org/blog/">PyTorch official blog</a>.
                        Below translation includes the original text. To read the original post, click <a href="https://pytorch.org/blog/pytorch2-3/">here</a>.)
                    </p>
                    
                    <div class="blog-content">
                        <p>PyTorch® 2.3(<a href="https://github.com/pytorch/pytorch/releases/tag/v2.3.0">릴리즈 노트</a>)의 출시를 발표하게 되어 기쁩니다! PyTorch 2.3은 torch.compile()에서 사용자 정의(user-defined) Triton 커널을 지원합니다. 사용자들은 성능 저하나 연산 그래프의 문제 없이 자체 트리톤 커널을 eager 모드에서 torch.compile()로 이전(migration)할 수 있습니다. Tensor Parallelism(텐서 병렬 처리)은 PyTorch 네이티브 함수를 사용하여 대규모 언어 모델(LLM, Large Language Models)을 학습하는 환경을 개선하였으며, 이는 1000억개 규모의 매개변수(100B parameter) 모델 학습을 통해 검증되었습니다. 또한, 반-구조적 희소성(Semi-structured sparsity)은 이를 Tensor 하위클래스(subclass)로 구현되어 밀집 행렬 곱셈(dense matrix multiplication) 대비 최대 1.6배의 속도 향상을 보입니다.</p>
<blockquote>
  <p>We are excited to announce the release of PyTorch® 2.3 (<a href="https://github.com/pytorch/pytorch/releases/tag/v2.3.0">release note</a>)! PyTorch 2.3 offers support for user-defined Triton kernels in torch.compile, allowing for users to migrate their own Triton kernels from eager without experiencing performance regressions or graph breaks. Tensor Parallelism improves the experience for training Large Language Models using native PyTorch functions, which has been validated on training runs for 100B parameter models. As well, semi-structured sparsity implements semi-structured sparsity as a Tensor subclass, with observed speedups of up to 1.6 over dense matrix multiplication.</p>
</blockquote>

<p>이번 릴리즈는 PyTorch 2.2 이후 426명의 기여자들로부터 3,393회의 커밋으로 구성되었습니다. 헌신적인 커뮤니티의 기여에 진심으로 감사드립니다. 언제나 그렇듯, 새로운 버전을 사용하시며 생기는 문제를 보고해주시면 PyTorch 2.3을 개선하는 데 도움이 됩니다. PyTorch 2 시리즈를 시작하는 방법에 대한 자세한 정보는 <a href="https://pytorch.kr/get-started/pytorch-2.0/">시작하기</a> 페이지에서 확인할 수 있습니다.</p>
<blockquote>
  <p>This release is composed of 3393 commits and 426 contributors since PyTorch 2.2. We want to sincerely thank our dedicated community for your contributions. As always, we encourage you to try these out and report any issues as we improve 2.3. More information about how to get started with the PyTorch 2-series can be found at our <a href="https://pytorch.org/get-started/pytorch-2.0/">Getting Started</a> page.</p>
</blockquote>

<table class="table table-bordered">
  <tr>
   <td><strong>Beta</strong></td>
   <td><strong>Prototype</strong></td>
   <td><strong>Performance Improvements</strong></td>
  </tr>
  <tr>
   <td>
      torch.compile에서 사용자 정의 Triton 커널 지원<br />
      <blockquote>User-defined Triton kernels in torch.compile</blockquote>
   </td>
   <td>
      torch.export에 dynamic_shape을 지정할 수 있는 새로운 API 추가<br />
      <blockquote>torch.export adds new API to specify dynamic_shapes</blockquote>
   </td>
   <td>
      Inductor CPU 백엔드에 가중치-전용-양자화 도입<br />
      <blockquote>Weight-Only-Quantization introduced into Inductor CPU backend</blockquote>
   </td>
  </tr>
  <tr>
   <td>
      PyTorch Distributed 내에서 텐서 병렬 처리<br />
      <blockquote>Tensor parallelism within PyTorch Distributed</blockquote>
   </td>
   <td>
      비동기 체크포인트 생성<br />
      <blockquote>Asynchronous checkpoint generation</blockquote>
   </td>
   <td></td>
  </tr>
  <tr>
   <td>반-구조적 희소성(Semi-structured sparsity) 지원<br />
      <blockquote>Support for semi-structured sparsity</blockquote>
   </td>
   <td></td>
   <td></td>
  </tr>
</table>

<ul>
  <li>공개된 기능 제출 목록은 <a href="https://docs.google.com/spreadsheets/d/1TzGkWuUMF1yTe88adz1dt2mzbIsZLd3PBasy588VWgk/edit?usp=sharing">여기</a>에서 확인할 수 있습니다.
    <blockquote>
      <ul>
        <li>To see a full list of public feature submissions click <a href="https://docs.google.com/spreadsheets/d/1TzGkWuUMF1yTe88adz1dt2mzbIsZLd3PBasy588VWgk/edit?usp=sharing">here</a>.</li>
      </ul>
    </blockquote>
  </li>
</ul>

<h2 id="베타-기능--beta-features">베타 기능 / Beta Features</h2>

<h3 id="베타-사용자-정의-triton-커널에-대한-torchcompile-지원--beta-support-for-user-defined-triton-kernels-in-torchcompile">[베타] 사용자 정의 Triton 커널에 대한 torch.compile 지원 / [Beta] Support for User-defined Triton kernels in <em>torch.compile</em></h3>

<p>torch.compile을 사용하여 Triton 커널이 포함된 PyTorch 코드를 네이티브로 실행할 수 있습니다. 이를 통해 Triton 커널이 포함된 코드를 eager PyTorch에서 <em>torch.compile</em> 로 성능 저하나 연산 그래프 문제 없이 이전할 수 있습니다. 네이티브 지원은 Torch Inductor가 사용자 정의 Triton 커널을 미리 컴파일(precomile)하여 Triton 커널 주변의 코드를 보다 효율적으로 구성함으로써 추가적인 최적화가 가능하게 합니다.</p>
<blockquote>
  <p>Allows for PyTorch code that contains triton kernels to be executed natively using torch.compile. This enables users to migrate code containing triton kernels from eager PyTorch to <em>torch.compile</em> without running into performance regressions or graph breaks. Native support also creates an opportunity for Torch Inductor to precompile the user-defined Triton kernel as well as better organize code around the Triton kernel allowing for further optimizations.</p>
</blockquote>

<p>torch.compile에서 사용자 정의 Triton 커널을 활용하는 방법에 대한 자세한 내용은 <a href="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">이 튜토리얼</a>에서 확인하세요.</p>
<blockquote>
  <p>You can find more information about how to utilize user defined Triton kernels in torch.compile within <a href="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">this tutorial</a>.</p>
</blockquote>

<h3 id="베타-텐서-병렬-처리를-통한-llm-학습-효율-향상--beta-tensor-parallelism-introduces-more-efficient-ways-to-train-llms">[베타] 텐서 병렬 처리를 통한 LLM 학습 효율 향상 / [Beta] Tensor Parallelism introduces more efficient ways to train LLMs</h3>

<p>텐서 병렬 처리(Tensor Parallel) API는 GPU와 호스트 간의 다양한 텐서 조작을 용이하게 하며, 2D 병렬 처리를 위해 FSDP와 통합되어 있습니다(장치 간 텐서 병렬 처리 + 호스트 간 데이터 병렬 처리). 또한, 고수준(higher-level)의 텐서 병렬 API 구성을 위해 저수준(low-level)의 API들을 제공합니다. 이 API는 1000억 개의 매개변수(100 billion parameters)를 가진 트랜스포머 모델의 학습을 지원함으로써 검증되었습니다.</p>
<blockquote>
  <p>The Tensor Parallel API facilitates various tensor manipulations across GPUs/hosts and integrates with FSDP for 2D Parallelism (Tensor parallelism across devices + Data Parallelism across hosts). It also offers a low-level API for constructing higher-level Tensor parallel APIs. This API has been validated to support the training of transformer models with over 100 billion parameters.</p>
</blockquote>

<p>이 API를 워크플로우 내에서 활용하는 방법에 대한 자세한 내용은 <a href="https://pytorch.org/tutorials/intermediate/TP_tutorial.html">이 튜토리얼</a>에서 확인하실 수 있습니다.</p>
<blockquote>
  <p>You can find more information on how to utilize this within your workflows within <a href="https://pytorch.org/tutorials/intermediate/TP_tutorial.html">this tutorial</a>.</p>
</blockquote>

<h3 id="베타-반-구조적-희소성으로-가속화된-희소-추론-및-메모리-절약--beta-semi-structured-sparsity-provides-users-with-a-way-to-take-advantage-of-accelerated-sparse-inference-and-memory-savings">[베타] 반-구조적 희소성으로 가속화된 희소 추론 및 메모리 절약 / [Beta] Semi-structured sparsity provides users with a way to take advantage of accelerated sparse inference and memory savings</h3>

<p>반구조적 희소성을 Tensor의 하위클래스인 <em>torch.sparse.SparseSemiStructuredTensor</em> 로 구현하였으며 밀집 행렬 곱셈(dense matrix multiplication) 대비 최대 1.6배의 속도 향상을 보였습니다.</p>
<blockquote>
  <p><em>torch.sparse.SparseSemiStructuredTensor</em> implements semi-structured sparsity as a Tensor subclass, which have observed speedups of up to 1.6 over dense matrix multiplication.</p>
</blockquote>

<p>특히, 다음과 같은 추가적인 기능을 제공합니다:</p>

<ul>
  <li>양자화 조합 기능(Quantization composability)을 위한 지원(mixed dtype, dequant fusion)</li>
  <li>업데이트된 cuSPARSELt 및 CUTLASS 커널</li>
  <li>torch.compile 지원</li>
</ul>

<blockquote>
  <p>In particular it adds:</p>

  <ul>
    <li>Additional support for quantization composability (mixed dtype, dequant fusion)</li>
    <li>Updated cuSPARSELt and CUTLASS kernels</li>
    <li>torch.compile support</li>
  </ul>
</blockquote>

<p>반-구조적 희소성 활용 시 이점에 대한 자세한 내용은 <a href="https://pytorch.org/tutorials/advanced/semi_structured_sparse.html">여기</a>에서 확인하실 수 있습니다.</p>
<blockquote>
  <p>You can find more information on how to take advantage of semi-structured sparsity <a href="https://pytorch.org/tutorials/advanced/semi_structured_sparse.html">here</a>.</p>
</blockquote>

<h2 id="프로토타입-기능--prototype-features">프로토타입 기능 / Prototype Features</h2>

<h3 id="프로토타입-torchexport_에-_dynamic_shapes-을-지정하는-api-추가--prototype-torchexport-adds-new-api-to-specify-dynamic_shapes">[프로토타입] <em>torch.export_에 _dynamic_shapes</em> 을 지정하는 API 추가 / [PROTOTYPE] <em>torch.export</em> adds new API to specify <em>dynamic_shapes</em></h3>

<p><em>torch.export.Dim</em> 을 사용하여 동적 형태(dynamic shapes)를 더 잘 표현할 수 있게 되었습니다. 이를 통해 개발자들은 동일하게 유지되어야 하는 서로 다른 입력 차원들 간의 범위(최소 및 최대 값)를 지정하여 재사용할 수 있게 되었습니다.</p>
<blockquote>
  <p>You can now use <em>torch.export.Dim</em> to better represent dynamic shapes by enabling developers to specify ranges (min and max values) that can be reused across different input dimensions that are constrained to be equal.</p>
</blockquote>

<p><em>torch.export.Dim</em> 에 대한 자세한 내용 및 이를 사용하여 선형 산술 표현식(linear arithmetic expressions)과 같은 더 흥미로운 관계를 표현하는 방법에 대해 더 알아보려면 <a href="https://pytorch.org/tutorials/intermediate/torch_export_tutorial.html#constraints-dynamic-shapes">여기</a>에서 튜토리얼을 확인하실 수 있습니다.</p>
<blockquote>
  <p>To learn more about <em>torch.export.Dim</em> as well as how it can be used to express more interesting relationships (such as linear arithmetic expressions) check out the tutorial <a href="https://pytorch.org/tutorials/intermediate/torch_export_tutorial.html#constraints-dynamic-shapes">here</a>.</p>
</blockquote>

<h3 id="프로토타입-비동기-체크포인트-생성--prototype-asynchronous-checkpoint-generation">[프로토타입] 비동기 체크포인트 생성 / [PROTOTYPE] Asynchronous checkpoint generation</h3>

<p>비동기 체크포인트 생성 기능은 체크포인트가 생성되는 동안 학습 루프를 계속할 수 있도록 하여, 체크포인트 생성 비용의 대부분을 절감(offload)할 수 있습니다.</p>
<blockquote>
  <p>Asynchronous checkpoint generation allows users to continue their training loops while checkpoints are being generated, essentially offloading much of the checkpointing cost.</p>
</blockquote>

<p>이 <a href="https://github.com/pytorch/pytorch/blob/release/2.3/torch/distributed/checkpoint/examples/async_checkpointing_example.py">예제</a>를 통해 이 기능을 워크플로우에서 활용하는 방법을 알아볼 수 있습니다.</p>
<blockquote>
  <p>You can find out how to utilize this within your own workflows with this <a href="https://github.com/pytorch/pytorch/blob/release/2.3/torch/distributed/checkpoint/examples/async_checkpointing_example.py">example</a>.</p>
</blockquote>

<h2 id="성능-개선--performance-improvements">성능 개선 / Performance Improvements</h2>

<h3 id="프로토타입-inductor-cpu-백엔드에-가중치-전용-양자화-도입--prototype-weight-only-quantization-introduced-into-inductor-cpu-backend">[프로토타입] Inductor CPU 백엔드에 가중치-전용-양자화 도입 / [PROTOTYPE] Weight-Only-Quantization introduced into Inductor CPU backend</h3>

<p>PyTorch 2.3에서는 torch inductor CPU 백엔드에서 LLM 추론 성능을 향상시켰습니다. <a href="https://github.com/pytorch-labs/gpt-fast">gpt-fast</a> 프로젝트는 <em>torch.compile</em> 을 사용하여 트랜스포머 텍스트 생성을 위해 간단하고 효율적인 PyTorch 네이티브 가속 기능을 지원합니다. 2.3 이전에는 CUDA 장치에서만 지원되었던 기능으로, int4 및 int8 가중치 전용 양자화 Linear에 대해 고도로 최적화된 커널을 제공함으로써 CPU 버전을 지원합니다.</p>
<blockquote>
  <p>PyTorch 2.3 enhances LLM inference performance on torch inductor CPU backend. The project <a href="https://github.com/pytorch-labs/gpt-fast">gpt-fast</a> offers a simple and efficient PyTorch native acceleration for transformer text generation with <em>torch.compile</em>. Prior to 2.3 only CUDA devices were supported and this feature enables the CPU counterpart by providing highly optimized kernels for the int4 and int8 weight only quantization Linear.</p>
</blockquote>

<p>이 기능을 활용하는 방법에 대한 자세한 정보는 <a href="https://github.com/pytorch-labs/gpt-fast#quantization">gpt-fast README</a>를 참고해주세요.</p>
<blockquote>
  <p>For more information / how to utilize this feature please refer to the <a href="https://github.com/pytorch-labs/gpt-fast#quantization">gpt-fast README</a>.</p>
</blockquote>

                    </div>
                    <hr noshade />
                    <p class="translation-description ad-discuss">
                         더 궁금하시거나 나누고 싶은 이야기가 있으신가요? <a href="https://discuss.pytorch.kr/">파이토치 한국어 커뮤니티에 참여</a>해주세요!
                    </p>
                </article>
            </div>
        </div>
    </div>

    <div class="blog-comment">
  <div class="container">
      <div id="discourse-comments"></div>
      <meta name="discourse-username" content="bot">
  </div>
</div>

<script type="text/javascript">
  DiscourseEmbed = {
      discourseUrl: 'https://discuss.pytorch.kr/',
      discourseEmbedUrl: 'https://pytorch.kr/blog/2024/pytorch2-3/',
      // className: 'CLASS_NAME',
  };

  (function() {
      var d = document.createElement('script'); d.type = 'text/javascript'; d.async = true;
      d.src = DiscourseEmbed.discourseUrl + 'javascripts/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(d);
  })();
</script>

    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="">파이토치 한국 사용자 모임</a></li>
          <li><a href="/about">사용자 모임 소개</a></li>
          <li><a href="/contributors">기여해주신 분들</a></li>
          <li><a href="/resources">리소스</a></li>
          <li><a href="/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LEHG248408"></script>
<script data-cfasync="false">
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LEHG248408');   // GA4
</script>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>

        <li class="main-menu-item ">
          <a href="/get-started">시작하기</a>
        </li>

        <li class="main-menu-item active">
          <a href="/blog">블로그</a>
        </li>

        <li class="main-menu-item">
          <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
        </li>

        <li class="main-menu-item">
          <a href="/hub">허브</a>
        </li>

        <li class="main-menu-item">
          <a href="https://discuss.pytorch.kr/">커뮤니티</a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>
<!-- 
  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script> -->

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .coc-header, .announcement-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>

<script src="/assets/track-events.js"></script>
<script>trackEvents.bind();</script>


</body>
</html>
