{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5abf04",
   "metadata": {},
   "source": [
    "### This notebook requires a GPU runtime to run.\n",
    "### Please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "# Tacotron 2\n",
    "\n",
    "*Author: NVIDIA*\n",
    "\n",
    "**The Tacotron 2 model for generating mel spectrograms from text**\n",
    "\n",
    "<img src=\"https://pytorch.org/assets/images/tacotron2_diagram.png\" alt=\"alt\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "\n",
    "### 모델 설명\n",
    "\n",
    "Tacotron 2 및 WaveGlow 모델은 추가 운율 정보 없이 원본 텍스트에서 자연스러운 음성을 합성할 수 있는 텍스트 음성 변환 시스템을 만듭니다. Tacotron 2 모델은 인코더-디코더 아키텍처를 사용하여 입력 텍스트에서 멜 스펙트로그램(mel spectrogram)을 생성합니다. WaveGlow (torch.hub를 통해서도 사용 가능)는 멜 스펙트로그램을 사용하여 음성을 생성하는 흐름 기반(flow-based) 모델입니다.\n",
    "\n",
    "사전 훈련된 Tacotron 2 모델은 논문과 다르게 구현되었습니다. 여기서 제공하는 모델에서는 LSTM 레이어를 정규화하기 위해 Zoneout 대신 Dropout을 사용합니다.\n",
    "\n",
    "### 예시 사례\n",
    "\n",
    "아래 예제에서는:\n",
    "- 사전 훈련된 Tacotron2 및 Waveglow 모델은 torch.hub에서 가져옵니다.\n",
    "- Tacotron2는 (\"Hello world, I miss you so much\")와 같은 입력 텍스트의 텐서 표현이 주어지면 그림과 같은 멜 스펙트로그램을 생성합니다. \n",
    "- Waveglow는 멜 스펙트로그램에서 사운드를 생성합니다.\n",
    "- 출력 사운드는 'audio.wav' 파일에 저장됩니다.\n",
    "\n",
    "이 예제를 실행하려면 몇 가지 추가 파이썬 패키지가 설치되어 있어야 합니다.\n",
    "이는 텍스트 및 오디오를 전처리하는 것은 물론 디스플레이 및 입출력 전처리에도 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ef877",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install numpy scipy librosa unidecode inflect librosa\n",
    "apt-get update\n",
    "apt-get install -y libsndfile1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b07fa4",
   "metadata": {},
   "source": [
    "[LJ Speech dataset](https://keithito.com/LJ-Speech-Dataset/) 데이터셋에서 사전 훈련된 Tacotron2 모델을 불러오고 추론을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65823d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91408d",
   "metadata": {},
   "source": [
    "사전 훈련된 WaveGlow 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ea168",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96210cd",
   "metadata": {},
   "source": [
    "모델이 다음과 같이 말하게 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb309e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world, I missed you so much.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d31392",
   "metadata": {},
   "source": [
    "유틸리티 메서드를 사용하여 입력 형식을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\n",
    "sequences, lengths = utils.prepare_input_sequence([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86c85a",
   "metadata": {},
   "source": [
    "연결된 모델을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mel, _, _ = tacotron2.infer(sequences, lengths)\n",
    "    audio = waveglow.infer(mel)\n",
    "audio_numpy = audio[0].data.cpu().numpy()\n",
    "rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acec1a3",
   "metadata": {},
   "source": [
    "파일로 저장하여 들어볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7672632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "write(\"audio.wav\", rate, audio_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea78ff",
   "metadata": {},
   "source": [
    "또는 IPython이 있는 노트북에서 바로 들어볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(audio_numpy, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cafec22",
   "metadata": {},
   "source": [
    "### 세부사항\n",
    "모델 입력 및 출력, 학습 방법, 추론 및 성능 등에 대한 더 자세한 정보는 [github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2) 및 and/or  [NGC](https://ngc.nvidia.com/catalog/resources/nvidia:tacotron_2_and_waveglow_for_pytorch)에서 볼 수 있습니다.\n",
    "\n",
    "### 참고문헌\n",
    "\n",
    " - [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)\n",
    " - [WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002)\n",
    " - [Tacotron2 and WaveGlow on NGC](https://ngc.nvidia.com/catalog/resources/nvidia:tacotron_2_and_waveglow_for_pytorch)\n",
    " - [Tacotron2 and Waveglow on github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
