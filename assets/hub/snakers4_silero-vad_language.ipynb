{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a7d540",
   "metadata": {},
   "source": [
    "### This notebook is optionally accelerated with a GPU runtime.\n",
    "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "# Silero Language Classifier\n",
    "\n",
    "*Author: Silero AI Team*\n",
    "\n",
    "**Pre-trained Spoken Language Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6350317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# this assumes that you have a proper version of PyTorch already installed\n",
    "pip install -q torchaudio soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from pprint import pprint\n",
    "# download example\n",
    "torch.hub.download_url_to_file('https://models.silero.ai/vad_models/de.wav', 'de_example.wav')\n",
    "\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_lang_detector',\n",
    "                              force_reload=True)\n",
    "\n",
    "get_language, read_audio, *_ = utils\n",
    "\n",
    "files_dir = torch.hub.get_dir() + '/snakers4_silero-vad_master/files'\n",
    "\n",
    "wav = read_audio('de_example.wav')\n",
    "language = get_language(wav, model)\n",
    "\n",
    "pprint(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862f879",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Silero VAD: pre-trained enterprise-grade Voice Activity Detector (VAD), Number Detector and Language Classifier (95 languages). Enterprise-grade Speech Products made refreshingly simple (see our STT models). **Each model is published separately**.\n",
    "\n",
    "Currently, there are hardly any high quality / modern / free / public voice activity detectors except for WebRTC Voice Activity Detector (link). WebRTC though starts to show its age and it suffers from many false positives.\n",
    "\n",
    "**(!!!) Important Notice (!!!)** - the models are intended to run on CPU only and were optimized for performance on 1 CPU thread. Note that the model is quantized.\n",
    "\n",
    "### Additional Examples and Benchmarks\n",
    "\n",
    "For additional examples and other model formats please visit this [link](https://github.com/snakers4/silero-vad) and please refer to the extensive examples in the Colab format (including the streaming examples).\n",
    "\n",
    "### References\n",
    "\n",
    "Language classifier model architecture is based on similar STT architectures.\n",
    "\n",
    "- [Silero VAD](https://github.com/snakers4/silero-vad)\n",
    "- [Alexander Veysov, \"Toward's an ImageNet Moment for Speech-to-Text\", The Gradient, 2020](https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/)\n",
    "- [Alexander Veysov, \"A Speech-To-Text Practitionerâ€™s Criticisms of Industry and Academia\", The Gradient, 2020](https://thegradient.pub/a-speech-to-text-practitioners-criticisms-of-industry-and-academia/)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
