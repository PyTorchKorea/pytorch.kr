<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      MEAL_V2 | 파이토치 한국 사용자 모임
    
  </title>
  <meta property="og:title" content="PyTorch Korea User Group" />
<meta
  name="description"
  property="og:description"
  content="(Unofficial) Korean user community for PyTorch which is an open source machine learning framework that accelerates the path from research prototyping to production deployment."
/>
<meta property="og:url" content="https://www.pytorch.kr" />
<meta property="og:type" content="website" />
<meta
  property="og:image"
  content="https://pytorch.kr/assets/images/pytorch-kr-logo.png"
/>
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
</head>

  <body class="hub hub-detail">
    <div class="container-fluid header-holder hub-header">
  <div class="container">
    

<div class="header-container">
  <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorchKR"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">시작하기</a>
    </li>

    <li class="main-menu-item">
      <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
    </li>

    <li class="main-menu-item active">
      <a href="/hub">허브</a>
    </li>

    <li class="main-menu-item">
      <a href="https://discuss.pytorch.kr">커뮤니티</a>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

  </div>
</div>


    <div class="main-background hub-background hub-detail-background"></div>

    <div class="jumbotron jumbotron-fluid">
      <div class="container">
        <span class="detail-arrow">
          
            <a href="/hub/research-models"><</a>
          
        </span>
        <h1>
          MEAL_V2
        </h1>

        <div class="row">
          <div class="col-md-6">
            <p class="detail-lead">By Carnegie Mellon University </p>
          </div>

          <div class="col-md-6">
            <p class="detail-lead lead-summary">Boosting Tiny and Efficient Models using Knowledge Distillation.</p>
            <a href="https://github.com/szq0214/MEAL-V2"><button class="btn btn-lg with-right-white-arrow detail-github-link">View on Github</button></a>
            <a href="https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/pytorch_vision_meal_v2.ipynb"><button class="btn btn-lg with-right-white-arrow detail-colab-link">Open on Google Colab</button></a>
          </div>
        </div>
      </div>
    </div>

    <div class="main-content-wrapper">
      <div class="main-content">
        <div class="container">
          <div class="row">
            <div class="col-md-4">
              <img src="/assets/images/MEALV2_method.png" data-image-name="MEALV2_method.png" class="featured-image img-fluid">
              <img src="/assets/images/MEALV2_results.png" data-image-name="MEALV2_results.png" class="featured-image img-fluid">
            </div>
            <div class="col-md-8">
              <article class="pytorch-article">
                <p>We require one additional Python dependency</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span>pip <span class="nb">install </span>timm
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># list of models: 'mealv1_resnest50', 'mealv2_resnest50', 'mealv2_resnest50_cutmix', 'mealv2_resnest50_380x380', 'mealv2_mobilenetv3_small_075', 'mealv2_mobilenetv3_small_100', 'mealv2_mobilenet_v3_large_100', 'mealv2_efficientnet_b0'
# load pretrained models, using "mealv2_resnest50_cutmix" as an example
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">hub</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'szq0214/MEAL-V2'</span><span class="p">,</span><span class="s">'meal_v2'</span><span class="p">,</span> <span class="s">'mealv2_resnest50_cutmix'</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div>

<p>All pre-trained models expect input images normalized in the same way,
i.e. mini-batches of 3-channel RGB images of shape <code class="language-plaintext highlighter-rouge">(3 x H x W)</code>, where <code class="language-plaintext highlighter-rouge">H</code> and <code class="language-plaintext highlighter-rouge">W</code> are expected to be at least <code class="language-plaintext highlighter-rouge">224</code>.
The images have to be loaded in to a range of <code class="language-plaintext highlighter-rouge">[0, 1]</code> and then normalized using <code class="language-plaintext highlighter-rouge">mean = [0.485, 0.456, 0.406]</code>
and <code class="language-plaintext highlighter-rouge">std = [0.229, 0.224, 0.225]</code>.</p>

<p>Here’s a sample execution.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Download an example image from the pytorch website
</span><span class="kn">import</span> <span class="nn">urllib</span>
<span class="n">url</span><span class="p">,</span> <span class="n">filename</span> <span class="o">=</span> <span class="p">(</span><span class="s">"https://github.com/pytorch/hub/raw/master/images/dog.jpg"</span><span class="p">,</span> <span class="s">"dog.jpg"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span> <span class="n">urllib</span><span class="p">.</span><span class="n">URLopener</span><span class="p">().</span><span class="n">retrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span> <span class="n">urllib</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># sample execution (requires torchvision)
</span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="n">input_image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># create a mini-batch as expected by the model
</span>
<span class="c1"># move the input and model to GPU for speed if available
</span><span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_batch</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span>
<span class="c1"># Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes
</span><span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># The output has unnormalized scores. To get probabilities, you can run a softmax on it.
</span><span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Download ImageNet labels
!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Read the categories
with open("imagenet_classes.txt", "r") as f:
    categories = [s.strip() for s in f.readlines()]
# Show top categories per image
top5_prob, top5_catid = torch.topk(probabilities, 5)
for i in range(top5_prob.size(0)):
    print(categories[top5_catid[i]], top5_prob[i].item())
</code></pre></div></div>

<h3 id="model-description">Model Description</h3>

<p>MEAL V2 models are from the <a href="https://arxiv.org/pdf/2009.08453.pdf">MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks</a> paper.</p>

<p>In this paper, we introduce a simple yet effective approach that can boost the vanilla ResNet-50 to 80%+ Top-1 accuracy on ImageNet without any tricks. Generally, our method is based on the recently proposed <a href="https://arxiv.org/abs/1812.02425">MEAL</a>, i.e., ensemble knowledge distillation via discriminators. We further simplify it through 1) adopting the similarity loss and discriminator only on the final outputs and 2) using the average of softmax probabilities from all teacher ensembles as the stronger supervision for distillation. One crucial perspective of our method is that the one-hot/hard label should not be used in the distillation process. We show that such a simple framework can achieve state-of-the-art results without involving any commonly-used tricks, such as 1) architecture modification; 2) outside training data beyond ImageNet; 3) autoaug/randaug; 4) cosine learning rate; 5) mixup/cutmix training; 6) label smoothing; etc.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Models</th>
      <th style="text-align: center">Resolution</th>
      <th style="text-align: center">#Parameters</th>
      <th style="text-align: center">Top-1/Top-5</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><a href="https://arxiv.org/abs/1812.02425">MEAL-V1 w/ ResNet50</a></td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">25.6M</td>
      <td style="text-align: center"><strong>78.21/94.01</strong></td>
      <td style="text-align: center"><a href="https://github.com/AaronHeee/MEAL#imagenet-model">GitHub</a></td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 w/ ResNet50</td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">25.6M</td>
      <td style="text-align: center"><strong>80.67/95.09</strong></td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 w/ ResNet50</td>
      <td style="text-align: center">380</td>
      <td style="text-align: center">25.6M</td>
      <td style="text-align: center"><strong>81.72/95.81</strong></td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 + CutMix w/ ResNet50</td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">25.6M</td>
      <td style="text-align: center"><strong>80.98/95.35</strong></td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 w/ MobileNet V3-Small 0.75</td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">2.04M</td>
      <td style="text-align: center"><strong>67.60/87.23</strong></td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 w/ MobileNet V3-Small 1.0</td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">2.54M</td>
      <td style="text-align: center"><strong>69.65/88.71</strong></td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 w/ MobileNet V3-Large 1.0</td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">5.48M</td>
      <td style="text-align: center"><strong>76.92/93.32</strong></td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">MEAL-V2 w/ EfficientNet-B0</td>
      <td style="text-align: center">224</td>
      <td style="text-align: center">5.29M</td>
      <td style="text-align: center"><strong>78.29/93.95</strong></td>
      <td style="text-align: center"> </td>
    </tr>
  </tbody>
</table>

<h3 id="references">References</h3>

<p>Please refer to our papers <a href="https://arxiv.org/pdf/2009.08453.pdf">MEAL V2</a>, <a href="https://arxiv.org/pdf/1812.02425.pdf">MEAL</a> for more details.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{shen2020mealv2,
    title={MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet without Tricks},
    author={Shen, Zhiqiang and Savvides, Marios},
    journal={arXiv preprint arXiv:2009.08453},
    year={2020}
}

@inproceedings{shen2019MEAL,
	title = {MEAL: Multi-Model Ensemble via Adversarial Learning},
	author = {Shen, Zhiqiang and He, Zhankui and Xue, Xiangyang},
	booktitle = {AAAI},
	year = {2019}
}
</code></pre></div></div>

                <a href=""><button class="btn btn-lg hub-feedback-button hub-flag">Not Working?</button></a>
              </article>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>공식 문서 (영어)</h2>
        <p>PyTorch 공식 문서입니다.</p>
        <a class="with-right-arrow" href="https://pytorch.org/docs" target="_blank">공식 문서로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 PyTorch 튜토리얼입니다.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>커뮤니티</h2>
        <p>다른 사용자들과 의견을 나눠보세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.org">PyTorch 홈페이지 (공식)</a></li>
          <li><a href="https://pytorch.org" target="_blank">공식 홈페이지</a></li>
          <li><a href="https://pytorch.org/tutorials" target="_blank">공식 튜토리얼</a></li>
          <li><a href="https://pytorch.org/docs" target="_blank">공식 문서</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="">한국 사용자 모임</a></li>
          <li><a href="/about">사이트 소개</a></li>
          <li><a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a></li>
          <li><a href="https://github.com/9bow/PyTorch-tutorials-kr" target="_blank">한국어 튜토리얼 저장소</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 PyTorch 한국어 사용자 커뮤니티로 Facebook, Inc와 관련이 없습니다. PyTorch, PyTorch 로고 및 모든 관련 표기는 Facebook, Inc의 상표입니다.</li>
        <li>This site is a user community and is not related with Facebook, Inc. PyTorch, the PyTorch logo and any related marks are trademarks of Facebook, Inc.</li>
      </ul>
    </div>
  </div>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156349638-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-156349638-1');
</script>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>

        <li class="main-menu-item ">
          <a href="/get-started">시작하기</a>
        </li>

        <li class="main-menu-item">
          <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
        </li>

        <li class="main-menu-item">
          <a href="/hub">허브</a>
        </li>

        <li class="main-menu-item">
          <a href="https://discuss.pytorch.kr">커뮤니티</a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>
<!-- 
  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script> -->

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>

<script src="/assets/track-events.js"></script>
<script>trackEvents.bind();</script>


  </body>
</html>

<script src="/assets/hub-detail.js"></script>
