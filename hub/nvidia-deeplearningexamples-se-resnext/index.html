<!DOCTYPE html>
<html lang="ko">
  <head>
<!-- Google Tag Manager -->
<script data-cfasync="false">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-57L6X5C');</script>
<!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      SE-ResNeXt101 | 파이토치 한국 사용자 모임
    
  </title>
  <meta property="og:title" content="파이토치 한국 사용자 모임 (PyTorch Korea User Group)" />
<meta
  name="description"
  property="og:description"
  content="파이토치 한국 사용자 모임에 오신 것을 환영합니다. 딥러닝 프레임워크인 파이토치(PyTorch)를 사용하는 한국어 사용자들을 위해 문서를 번역하고 정보를 공유하고 있습니다."
/>
<meta property="og:url" content="https://pytorch.kr" />
<meta property="og:type" content="website" />
<meta
  property="og:image"
  content="https://pytorch.kr/assets/images/pytorch-kr-logo.png"
/>
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
</head>

  <body class="hub hub-detail">
    <!-- Google Tag Manager (noscript) -->
<noscript data-cfasync="false"><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-57L6X5C"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

    <div class="container-fluid header-holder hub-header">
  <div class="container">
    

<div class="header-container">
  <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorchKR"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">시작하기</a>
    </li>

    <li class="main-menu-item ">
      <a href="/blog">블로그</a>
    </li>

    <li class="main-menu-item">
      <a href="https://tutorials.pytorch.kr/" target="_self">튜토리얼</a>
    </li>

    <li class="main-menu-item active">
      <a href="/hub">허브</a>
    </li>

    <li class="main-menu-item">
      <a href="https://discuss.pytorch.kr/" target="_self">커뮤니티</a>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

  </div>
</div>


    <div class="main-background hub-background hub-detail-background"></div>

    <div class="jumbotron jumbotron-fluid">
      <div class="container">
        <span class="detail-arrow">
          
            <a href="/hub/research-models"><</a>
          
        </span>
        <h1>
          SE-ResNeXt101
        </h1>

        <div class="row">
          <div class="col-md-4">
            <p class="detail-lead">By NVIDIA </p>
          </div>

          <div class="col-md-8">
            <p class="detail-lead lead-summary">ResNeXt with Squeeze-and-Excitation module added, trained with mixed precision using Tensor Cores.</p>
            <div class="detail-button-container">
              <a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/se-resnext101-32x4d"><button class="btn btn-lg with-right-white-arrow detail-github-link">View on Github</button></a>
              <a href="https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/nvidia_deeplearningexamples_se-resnext.ipynb"><button class="btn btn-lg with-right-white-arrow detail-colab-link">Open on Google Colab</button></a>
              
                
                  <a href="https://huggingface.co/spaces/pytorch/SE-ResNeXt101"><button class="btn btn-lg with-right-white-arrow detail-web-demo-link">Open Model Demo</button></a>
                
              
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="main-content-wrapper">
      <div class="main-content">
        <div class="container">
          <div class="row">
            <div class="col-md-4">
              <img src="/assets/images/SEArch.png" data-image-name="SEArch.png" class="featured-image img-fluid">
              <img src="/assets/images/classification.jpg" data-image-name="classification.jpg" class="featured-image img-fluid">
            </div>
            <div class="col-md-8">
              <article class="pytorch-article">
                <h3 id="model-description">Model Description</h3>

<p>The <strong><em>SE-ResNeXt101-32x4d</em></strong> is a <a href="https://arxiv.org/pdf/1611.05431.pdf">ResNeXt101-32x4d</a>
model with added Squeeze-and-Excitation module introduced
in the <a href="https://arxiv.org/pdf/1709.01507.pdf">Squeeze-and-Excitation Networks</a> paper.</p>

<p>This model is trained with mixed precision using Tensor Cores on Volta, Turing, and the NVIDIA Ampere GPU architectures. Therefore, researchers can get results 3x faster than training without Tensor Cores, while experiencing the benefits of mixed precision training. This model is tested against each NGC monthly container release to ensure consistent accuracy and performance over time.</p>

<p>We use <a href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html">NHWC data layout</a> when training using Mixed Precision.</p>

<h4 id="model-architecture">Model architecture</h4>

<p><img src="https://pytorch.org/assets/images/SEArch.png" alt="SEArch" /></p>

<p><em>Image source: <a href="https://arxiv.org/pdf/1709.01507.pdf">Squeeze-and-Excitation Networks</a></em></p>

<p>Image shows the architecture of SE block and where is it placed in ResNet bottleneck block.</p>

<p>Note that the SE-ResNeXt101-32x4d model can be deployed for inference on the <a href="https://github.com/NVIDIA/trtis-inference-server">NVIDIA Triton Inference Server</a> using TorchScript, ONNX Runtime or TensorRT as an execution backend. For details check <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/resources/se_resnext_for_triton_from_pytorch">NGC</a>.</p>

<h3 id="example">Example</h3>

<p>In the example below we will use the pretrained <strong><em>SE-ResNeXt101-32x4d</em></strong> model to perform inference on images and present the result.</p>

<p>To run the example you need some extra python packages installed. These are needed for preprocessing images and visualization.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">validators</span> <span class="n">matplotlib</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="n">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> for inference</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p>Load the model pretrained on IMAGENET dataset.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resneXt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">hub</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">NVIDIA/DeepLearningExamples:torchhub</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nvidia_se_resnext101_32x4d</span><span class="sh">'</span><span class="p">)</span>
<span class="n">utils</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">hub</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">NVIDIA/DeepLearningExamples:torchhub</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nvidia_convnets_processing_utils</span><span class="sh">'</span><span class="p">)</span>

<span class="n">resneXt</span><span class="p">.</span><span class="nf">eval</span><span class="p">().</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Prepare sample input data.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uris</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">'</span><span class="s">http://images.cocodataset.org/test-stuff2017/000000024309.jpg</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">http://images.cocodataset.org/test-stuff2017/000000028117.jpg</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">http://images.cocodataset.org/test-stuff2017/000000006149.jpg</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">http://images.cocodataset.org/test-stuff2017/000000004954.jpg</span><span class="sh">'</span><span class="p">,</span>
<span class="p">]</span>


<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">utils</span><span class="p">.</span><span class="nf">prepare_input_from_uri</span><span class="p">(</span><span class="n">uri</span><span class="p">)</span> <span class="k">for</span> <span class="n">uri</span> <span class="ow">in</span> <span class="n">uris</span><span class="p">]</span>
<span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Run inference. Use <code class="language-plaintext highlighter-rouge">pick_n_best(predictions=output, n=topN)</code> helper function to pick N most probable hypotheses according to the model.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="nf">resneXt</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
<span class="n">results</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="nf">pick_n_best</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">output</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<p>Display the result.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">uri</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">uris</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">uri</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">raw</span><span class="p">)</span>
    <span class="n">img</span><span class="p">.</span><span class="nf">thumbnail</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">),</span> <span class="n">Image</span><span class="p">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

</code></pre></div></div>

<h3 id="details">Details</h3>
<p>For detailed information on model input and output, training recipies, inference and performance visit:
<a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/se-resnext101-32x4d">github</a>
and/or <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/resources/se_resnext_for_pytorch">NGC</a>.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://arxiv.org/pdf/1709.01507.pdf">Squeeze-and-Excitation Networks</a></li>
  <li><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/se-resnext101-32x4d">model on github</a></li>
  <li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/resources/se_resnext_for_pytorch">model on NGC</a></li>
  <li><a href="https://catalog.ngc.nvidia.com/orgs/nvidia/models/seresnext101_32x4d_pyt_amp">pretrained model on NGC</a></li>
</ul>

                <a href="https://github.com/PyTorchKorea/hub-kr/issues"><button class="btn btn-lg hub-feedback-button hub-flag">Not Working?</button></a>
              </article>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="">파이토치 한국 사용자 모임</a></li>
          <li><a href="/about">사용자 모임 소개</a></li>
          <li><a href="/contributors">기여해주신 분들</a></li>
          <li><a href="/resources">리소스</a></li>
          <li><a href="/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LEHG248408"></script>
<script data-cfasync="false">
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LEHG248408');   // GA4
</script>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>

        <li class="main-menu-item ">
          <a href="/get-started">시작하기</a>
        </li>

        <li class="main-menu-item ">
          <a href="/blog">블로그</a>
        </li>

        <li class="main-menu-item">
          <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
        </li>

        <li class="main-menu-item">
          <a href="/hub">허브</a>
        </li>

        <li class="main-menu-item">
          <a href="https://discuss.pytorch.kr/">커뮤니티</a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>
<!-- 
  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script> -->

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .coc-header, .announcement-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>

<script src="/assets/track-events.js"></script>
<script>trackEvents.bind();</script>


  </body>
</html>

<script src="/assets/hub-detail.js"></script>
